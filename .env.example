# Smart Farming - Environment Configuration
# Copy this file to .env and fill in your values

# ============================================================================
# SUPABASE CONFIGURATION (Frontend)
# ============================================================================
VITE_SUPABASE_URL=your_supabase_url_here
VITE_SUPABASE_ANON_KEY=your_supabase_anon_key_here

# ============================================================================
# SUPABASE CONFIGURATION (Backend)
# ============================================================================
SUPABASE_URL=your_supabase_url_here
SUPABASE_ANON_KEY=your_supabase_anon_key_here
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key_here

# ============================================================================
# TWILIO CONFIGURATION (For OTP)
# ============================================================================
TWILIO_ACCOUNT_SID=your_twilio_account_sid
TWILIO_AUTH_TOKEN=your_twilio_auth_token
TWILIO_PHONE_NUMBER=your_twilio_phone_number

# ============================================================================
# PYTHON AI BACKEND (Recommendations)
# ============================================================================
PYTHON_AI_URL=http://localhost:8000

# ============================================================================
# OLLAMA CHATBOT CONFIGURATION (AI Support for Farmers)
# ============================================================================

# Ollama server URL (local or remote)
# Default: http://localhost:11434
# If running locally: http://localhost:11434
# If running on another machine: http://192.168.x.x:11434
OLLAMA_URL=http://localhost:11434

# Ollama model to use
# Lightweight options (good for CPU-only):
# - mistral:7b (fast, smart, recommended)
# - neural-chat:7b (optimized for conversation)
# - orca-mini:3b (super lightweight)
# - llama2:7b (good general knowledge)
# - phi:latest (very fast for simple queries)
#
# GPU-optimized models:
# - mistral:latest (fast with GPU)
# - neural-chat:latest (faster with GPU)
OLLAMA_MODEL=mistral:7b

# ============================================================================
# PING MESSAGE (For API Health Check)
# ============================================================================
PING_MESSAGE=pong

# ============================================================================
# APPLICATION CONFIGURATION
# ============================================================================
NODE_ENV=development

# ============================================================================
# MQTT BROKER CONFIGURATION (For IoT Irrigation)
# ============================================================================
# MQTT broker address (local or cloud)
# Examples:
# - Local: localhost or 127.0.0.1
# - Cloud: broker.hivemq.com, mqtt.eclipseprojects.io
# - Mosquitto: test.mosquitto.org
MQTT_BROKER_HOST=localhost
MQTT_BROKER_PORT=1883

# Optional MQTT authentication
MQTT_USERNAME=
MQTT_PASSWORD=
